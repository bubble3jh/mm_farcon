{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a731f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bubble3jh/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import logging\n",
    "import pandas as pd\n",
    "import glob \n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import UnidentifiedImageError\n",
    "import subprocess\n",
    "from weat.test import Test\n",
    "import torch\n",
    "import clip\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda:2\")\n",
    "print(device)\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "\n",
    "class dwebpException(Exception):\n",
    "    pass\n",
    "\n",
    "def dwebp(file: str):\n",
    "    webp = subprocess.run(\n",
    "        f\"dwebp  {file} -quiet -o -\", shell=True, capture_output=True\n",
    "    )\n",
    "    if webp.returncode != 0:\n",
    "        raise dwebpException(webp.stderr.decode())\n",
    "    else:\n",
    "        return Image.open(BytesIO(webp.stdout))\n",
    "\n",
    "def load_dir(path):\n",
    "    tmp = []\n",
    "    \n",
    "    for file in glob.glob(path):\n",
    "        # 파일 확장자가 .json이면 무시\n",
    "        if os.path.splitext(file)[1].lower() == \".json\":\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                img = Image.open(file)\n",
    "            except UnidentifiedImageError:\n",
    "                if os.path.splitext(file)[1].lower() == \".webp\":\n",
    "                    img = dwebp(file)\n",
    "                  \n",
    "                else:\n",
    "                    raise\n",
    "            prep = preprocess(img).unsqueeze(0).to(device)\n",
    "            emb = model.encode_image(prep)\n",
    "            tmp.append(emb.cpu())\n",
    "    return tmp\n",
    "\n",
    "def ieat_calc(X_Image_Paths, Y_Image_Paths, A_texts, B_texts, Names):\n",
    "    df = pd.DataFrame(columns=['Name', 'X', 'Y', 'A', 'B', 'n_t', 'n_a', 'p_i', 'd_i'])\n",
    "    for i in range(len(Names[0])):\n",
    "        X_image = torch.cat(load_dir(f'{X_Image_Paths[i]}*'))\n",
    "        Y_image = torch.cat(load_dir(f'{Y_Image_Paths[i]}*'))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            A_text = model.encode_text(A_texts[i]).to(\"cpu\")\n",
    "            B_text = model.encode_text(B_texts[i]).to(\"cpu\")\n",
    "                \n",
    "        test = Test(X_image, Y_image, A_text, B_text)\n",
    "        out = test.run()\n",
    "        result = {\n",
    "            'Name': Names[0][i],\n",
    "            'X': Names[1][i],\n",
    "            'Y': Names[2][i],\n",
    "            'A': Names[3][i],\n",
    "            'B': Names[4][i],\n",
    "            'n_t': X_image.shape[0],\n",
    "            'n_a': A_text.shape[0], \n",
    "            'p_i': out[1],\n",
    "            'd_i': out[0]\n",
    "        }\n",
    "        df = df.append(result, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "def load_caption(load_dir, model, device):\n",
    "    # 1. JSON 파일 읽기\n",
    "    with open(load_dir+'captions.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 2. \"caption\" 키의 값만 추출\n",
    "    captions = [item['caption'] for item in data]\n",
    "\n",
    "    return model.encode_text(clip.tokenize(captions).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171b77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dwebpException(Exception):\n",
    "    pass\n",
    "\n",
    "def dwebp(file: str):\n",
    "    webp = subprocess.run(\n",
    "        f\"dwebp  {file} -quiet -o -\", shell=True, capture_output=True\n",
    "    )\n",
    "    if webp.returncode != 0:\n",
    "        raise dwebpException(webp.stderr.decode())\n",
    "    else:\n",
    "        return Image.open(BytesIO(webp.stdout))\n",
    "\n",
    "def load_dir(path):\n",
    "    tmp = []\n",
    "    \n",
    "    for file in glob.glob(path):\n",
    "        # 파일 확장자가 .json이면 무시\n",
    "        if os.path.splitext(file)[1].lower() == \".json\":\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                img = Image.open(file)\n",
    "            except UnidentifiedImageError:\n",
    "                if os.path.splitext(file)[1].lower() == \".webp\":\n",
    "                    img = dwebp(file)\n",
    "                  \n",
    "                else:\n",
    "                    raise\n",
    "            prep = preprocess(img).unsqueeze(0).to(device)\n",
    "            emb = model.encode_image(prep)\n",
    "            tmp.append(emb.cpu())\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29583a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ieat_calc(X_Image_Paths, Y_Image_Paths, A_texts, B_texts, Names):\n",
    "    df = pd.DataFrame(columns=['Name', 'X', 'Y', 'A', 'B', 'n_t', 'n_a', 'p_i', 'd_i'])\n",
    "    for i in range(len(Names[0])):\n",
    "        X_image = torch.cat(load_dir(f'{X_Image_Paths[i]}*'))\n",
    "        Y_image = torch.cat(load_dir(f'{Y_Image_Paths[i]}*'))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            A_text = model.encode_text(A_texts[i]).to(\"cpu\")\n",
    "            B_text = model.encode_text(B_texts[i]).to(\"cpu\")\n",
    "                \n",
    "        test = Test(X_image, Y_image, A_text, B_text)\n",
    "        out = test.run()\n",
    "        result = {\n",
    "            'Name': Names[0][i],\n",
    "            'X': Names[1][i],\n",
    "            'Y': Names[2][i],\n",
    "            'A': Names[3][i],\n",
    "            'B': Names[4][i],\n",
    "            'n_t': X_image.shape[0],\n",
    "            'n_a': A_text.shape[0], \n",
    "            'p_i': out[1],\n",
    "            'd_i': out[0]\n",
    "        }\n",
    "        df = df.append(result, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1919689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "def load_caption(load_dir, model, device):\n",
    "    # 1. JSON 파일 읽기\n",
    "    with open(load_dir+'captions.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 2. \"caption\" 키의 값만 추출\n",
    "    captions = [item['caption'] for item in data]\n",
    "\n",
    "    return model.encode_text(clip.tokenize(captions).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601546e2",
   "metadata": {},
   "source": [
    "### Naive image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbffefa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02 11:26:30 PM: Computing cosine similarities...\n",
      "11/02 11:26:30 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:26:30 PM: Computing pval...\n",
      "11/02 11:26:30 PM: Using non-parametric test\n",
      "11/02 11:26:30 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:26:30 PM: pval: 0.0096\n",
      "11/02 11:26:30 PM: computing effect size...\n",
      "11/02 11:26:30 PM: esize: 0.445199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.445199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i       d_i\n",
       "0  Gender  Male  Female  Science  Arts   55   55  0.0096  0.445199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "\n",
    "A_text = load_caption('./gender/science/', model, device).detach().to(\"cpu\")\n",
    "B_text = load_caption('./gender/liberal-arts/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e45d8",
   "metadata": {},
   "source": [
    "### Swapped image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953aebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02 11:16:21 PM: Computing cosine similarities...\n",
      "11/02 11:16:21 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:16:21 PM: Computing pval...\n",
      "11/02 11:16:21 PM: Using non-parametric test\n",
      "11/02 11:16:21 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:16:21 PM: pval: 0.0034\n",
      "11/02 11:16:21 PM: computing effect size...\n",
      "11/02 11:16:21 PM: esize: 0.514824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.514824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i       d_i\n",
       "0  Gender  Male  Female  Science  Arts   55   55  0.0034  0.514824"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "# Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "\n",
    "# A_text = load_caption('./gender/science/', model, device).detach().to(\"cpu\")\n",
    "# B_text = load_caption('./gender/liberal-arts/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "X_image = torch.cat(load_dir('./gender/science/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/liberal-arts/*'))\n",
    "\n",
    "A_text = load_caption('./gender/male/', model, device).detach().to(\"cpu\")\n",
    "B_text = load_caption('./gender/female/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3859976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02 11:47:44 PM: Computing cosine similarities...\n",
      "11/02 11:47:44 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:47:44 PM: Computing pval...\n",
      "11/02 11:47:44 PM: Using non-parametric test\n",
      "11/02 11:47:44 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:47:44 PM: pval: 0.0031\n",
      "11/02 11:47:44 PM: computing effect size...\n",
      "11/02 11:47:44 PM: esize: 0.514824\n",
      "11/02 11:47:53 PM: Computing cosine similarities...\n",
      "11/02 11:47:53 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:47:53 PM: Computing pval...\n",
      "11/02 11:47:53 PM: Using non-parametric test\n",
      "11/02 11:47:53 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:47:53 PM: pval: 0.0029\n",
      "11/02 11:47:53 PM: computing effect size...\n",
      "11/02 11:47:53 PM: esize: 0.502419\n",
      "11/02 11:48:00 PM: Computing cosine similarities...\n",
      "11/02 11:48:00 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:48:00 PM: Computing pval...\n",
      "11/02 11:48:00 PM: Using non-parametric test\n",
      "11/02 11:48:00 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:48:00 PM: pval: 0.0002\n",
      "11/02 11:48:00 PM: computing effect size...\n",
      "11/02 11:48:00 PM: esize: 0.637213\n",
      "11/02 11:48:06 PM: Computing cosine similarities...\n",
      "11/02 11:48:06 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:48:06 PM: Computing pval...\n",
      "11/02 11:48:06 PM: Using non-parametric test\n",
      "11/02 11:48:06 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:48:06 PM: pval: 0.0175\n",
      "11/02 11:48:06 PM: computing effect size...\n",
      "11/02 11:48:06 PM: esize: 0.407544\n",
      "11/02 11:48:12 PM: Computing cosine similarities...\n",
      "11/02 11:48:12 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:48:12 PM: Computing pval...\n",
      "11/02 11:48:12 PM: Using non-parametric test\n",
      "11/02 11:48:12 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:48:12 PM: pval: 0.0004\n",
      "11/02 11:48:12 PM: computing effect size...\n",
      "11/02 11:48:12 PM: esize: 0.685857\n",
      "11/02 11:48:18 PM: Computing cosine similarities...\n",
      "11/02 11:48:18 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:48:18 PM: Computing pval...\n",
      "11/02 11:48:18 PM: Using non-parametric test\n",
      "11/02 11:48:18 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:48:18 PM: pval: 0.0007\n",
      "11/02 11:48:18 PM: computing effect size...\n",
      "11/02 11:48:18 PM: esize: 0.587327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              A_attribute  \\\n",
      "0                             gender/male   \n",
      "1               intersectional/white-male   \n",
      "2                arab-muslim/other-people   \n",
      "3  american_race/european-american-google   \n",
      "4  american_race/european-american-google   \n",
      "5                      sexuality/straight   \n",
      "\n",
      "                             B_attribute              cap1  \\\n",
      "0                          gender/female    gender/science   \n",
      "1            intersectional/black-female    gender/science   \n",
      "2                arab-muslim/arab-muslim  valence/pleasant   \n",
      "3  american_race/african-american-google  valence/pleasant   \n",
      "4    american_race/asian-american-google  valence/pleasant   \n",
      "5                          sexuality/gay  valence/pleasant   \n",
      "\n",
      "                  cap2  n_X_images  n_Y_images  n_A_text  n_B_text  \\\n",
      "0  gender/liberal-arts          55          55        55        55   \n",
      "1  gender/liberal-arts          55          55        55        55   \n",
      "2   valence/unpleasant          55          55        55        55   \n",
      "3   valence/unpleasant          55          55        55        55   \n",
      "4   valence/unpleasant          55          55        55        55   \n",
      "5   valence/unpleasant          55          55        55        55   \n",
      "\n",
      "                     test_result  \n",
      "0   (0.5148241077222294, 0.0031)  \n",
      "1    (0.502418727285558, 0.0029)  \n",
      "2   (0.6372129689997778, 0.0002)  \n",
      "3  (0.40754352522685333, 0.0175)  \n",
      "4   (0.6858566766014681, 0.0004)  \n",
      "5   (0.5873266093180514, 0.0007)  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Presuming load_dir and load_caption are defined functions that load the images and captions\n",
    "# and Test is a class that has been defined to take images and captions and run some kind of test\n",
    "\n",
    "# The pairs as provided\n",
    "pairs = [\n",
    "  \"gender/male:gender/female:gender/science:gender/liberal-arts\",\n",
    "  \"intersectional/white-male:intersectional/black-female:gender/science:gender/liberal-arts\",\n",
    "  \"arab-muslim/other-people:arab-muslim/arab-muslim:valence/pleasant:valence/unpleasant\",\n",
    "  \"american_race/european-american-google:american_race/african-american-google:valence/pleasant:valence/unpleasant\",\n",
    "  \"american_race/european-american-google:american_race/asian-american-google:valence/pleasant:valence/unpleasant\",\n",
    "  \"sexuality/straight:sexuality/gay:valence/pleasant:valence/unpleasant\",\n",
    "]\n",
    "\n",
    "# Prepare a list to hold DataFrame rows\n",
    "df_rows = []\n",
    "\n",
    "# Iterate over the pairs to perform tests and collect results\n",
    "for pair_string in pairs:\n",
    "    # Split each pair string into its respective parts\n",
    "    A_attribute, B_attribute, cap1, cap2 = pair_string.split(':')\n",
    "\n",
    "    # Load images\n",
    "    X_images = torch.cat(load_dir(f'./{cap1}/*'))\n",
    "    Y_images = torch.cat(load_dir(f'./{cap2}/*'))\n",
    "\n",
    "    # Load captions\n",
    "    A_text = load_caption(f'./{A_attribute}/', model, device).detach().to(\"cpu\")\n",
    "    B_text = load_caption(f'./{B_attribute}/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "    # Perform the test\n",
    "    test = Test(X_images, Y_images, A_text, B_text)\n",
    "    out = test.run()\n",
    "\n",
    "    # Create a dictionary for the current row and append to the list\n",
    "    df_row = {\n",
    "        'A_attribute': A_attribute,\n",
    "        'B_attribute': B_attribute,\n",
    "        'cap1': cap1,\n",
    "        'cap2': cap2,\n",
    "        'n_X_images': X_images.shape[0],\n",
    "        'n_Y_images': Y_images.shape[0],\n",
    "        'n_A_text': A_text.shape[0],\n",
    "        'n_B_text': B_text.shape[0],\n",
    "        'test_result': out  # Assuming 'out' is a result that can be stored directly; adjust as needed\n",
    "    }\n",
    "    df_rows.append(df_row)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(df_rows)\n",
    "\n",
    "# Display or save the DataFrame as needed\n",
    "print(df)\n",
    "df.to_csv('swapped_biased_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74669d13",
   "metadata": {},
   "source": [
    "### FarconVAE Neutralized image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704076bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/02 11:50:29 PM: Computing cosine similarities...\n",
      "11/02 11:50:29 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/02 11:50:29 PM: Computing pval...\n",
      "11/02 11:50:29 PM: Using non-parametric test\n",
      "11/02 11:50:29 PM: Drawing 9999 samples (and biasing by 1)\n",
      "11/02 11:50:29 PM: pval: 0.1421\n",
      "11/02 11:50:29 PM: computing effect size...\n",
      "11/02 11:50:29 PM: esize: 0.206255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.206255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i       d_i\n",
       "0  Gender  Male  Female  Science  Arts   55   15  0.1421  0.206255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_image = torch.cat(load_dir('./gender/science/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/liberal-arts/*'))\n",
    "\n",
    "A_text = torch.load('/data1/bubble3jh/farcon/git_FarconVAE/neut_embeddings/imgs/gender/male_ViT-L14.pt').detach().to(\"cpu\")\n",
    "B_text = torch.load('/data1/bubble3jh/farcon/git_FarconVAE/neut_embeddings/imgs/gender/female_ViT-L14.pt').detach().to(\"cpu\")\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03 12:13:24 AM: Computing cosine similarities...\n",
      "11/03 12:13:24 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:24 AM: Computing pval...\n",
      "11/03 12:13:24 AM: Using non-parametric test\n",
      "11/03 12:13:24 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:24 AM: pval: 0.1406\n",
      "11/03 12:13:24 AM: computing effect size...\n",
      "11/03 12:13:24 AM: esize: 0.206255\n",
      "11/03 12:13:30 AM: Computing cosine similarities...\n",
      "11/03 12:13:30 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:30 AM: Computing pval...\n",
      "11/03 12:13:30 AM: Using non-parametric test\n",
      "11/03 12:13:30 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:30 AM: pval: 0.1472\n",
      "11/03 12:13:30 AM: computing effect size...\n",
      "11/03 12:13:30 AM: esize: 0.206256\n",
      "11/03 12:13:35 AM: Computing cosine similarities...\n",
      "11/03 12:13:35 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:35 AM: Computing pval...\n",
      "11/03 12:13:35 AM: Using non-parametric test\n",
      "11/03 12:13:35 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:35 AM: pval: 0.0001\n",
      "11/03 12:13:35 AM: computing effect size...\n",
      "11/03 12:13:35 AM: esize: 1.4398\n",
      "11/03 12:13:40 AM: Computing cosine similarities...\n",
      "11/03 12:13:40 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:40 AM: Computing pval...\n",
      "11/03 12:13:40 AM: Using non-parametric test\n",
      "11/03 12:13:40 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:40 AM: pval: 0.409\n",
      "11/03 12:13:40 AM: computing effect size...\n",
      "11/03 12:13:40 AM: esize: 0.0472484\n",
      "11/03 12:13:45 AM: Computing cosine similarities...\n",
      "11/03 12:13:45 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:45 AM: Computing pval...\n",
      "11/03 12:13:45 AM: Using non-parametric test\n",
      "11/03 12:13:45 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:45 AM: pval: 0.0006\n",
      "11/03 12:13:45 AM: computing effect size...\n",
      "11/03 12:13:45 AM: esize: 0.627127\n",
      "11/03 12:13:50 AM: Computing cosine similarities...\n",
      "11/03 12:13:50 AM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "11/03 12:13:50 AM: Computing pval...\n",
      "11/03 12:13:50 AM: Using non-parametric test\n",
      "11/03 12:13:50 AM: Drawing 9999 samples (and biasing by 1)\n",
      "11/03 12:13:50 AM: pval: 0.0092\n",
      "11/03 12:13:50 AM: computing effect size...\n",
      "11/03 12:13:50 AM: esize: 0.442937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name         X             Y  \\\n",
      "0                      gender/male vs. gender/female   science  liberal-arts   \n",
      "1  intersectional/white-male vs. intersectional/b...   science  liberal-arts   \n",
      "2  arab-muslim/other-people vs. arab-muslim/arab-...  pleasant    unpleasant   \n",
      "3  american_race/european-american-google vs. ame...  pleasant    unpleasant   \n",
      "4  american_race/european-american-google vs. ame...  pleasant    unpleasant   \n",
      "5               sexuality/straight vs. sexuality/gay  pleasant    unpleasant   \n",
      "\n",
      "                          A                        B  n_t  n_a     p_i  \\\n",
      "0                      male                   female   55   15  0.1406   \n",
      "1                white-male             black-female   55   15  0.1472   \n",
      "2              other-people              arab-muslim   55   10  0.0001   \n",
      "3  european-american-google  african-american-google   55   39  0.4090   \n",
      "4  european-american-google    asian-american-google   55   39  0.0006   \n",
      "5                  straight                      gay   55    8  0.0092   \n",
      "\n",
      "        d_i  \n",
      "0  0.206255  \n",
      "1  0.206256  \n",
      "2  1.439798  \n",
      "3  0.047248  \n",
      "4  0.627127  \n",
      "5  0.442937  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming load_dir and Test are defined functions/classes\n",
    "# and the embeddings for A_text and B_text are stored at specified paths\n",
    "\n",
    "# The pairs as provided\n",
    "pairs = [\n",
    "  \"gender/male:gender/female:gender/science:gender/liberal-arts\",\n",
    "  \"intersectional/white-male:intersectional/black-female:gender/science:gender/liberal-arts\",\n",
    "  \"arab-muslim/other-people:arab-muslim/arab-muslim:valence/pleasant:valence/unpleasant\",\n",
    "  \"american_race/european-american-google:american_race/african-american-google:valence/pleasant:valence/unpleasant\",\n",
    "  \"american_race/european-american-google:american_race/asian-american-google:valence/pleasant:valence/unpleasant\",\n",
    "  \"sexuality/straight:sexuality/gay:valence/pleasant:valence/unpleasant\",\n",
    "]\n",
    "\n",
    "# Prepare a list to hold DataFrame rows\n",
    "df_rows = []\n",
    "\n",
    "# Path to the neutral embeddings\n",
    "neut_embedding_base_path = '/data1/bubble3jh/farcon/git_FarconVAE/neut_embeddings/imgs/'\n",
    "\n",
    "# Iterate over the pairs to perform tests and collect results\n",
    "for pair_string in pairs:\n",
    "    # Split each pair string into its respective parts\n",
    "    A_attribute, B_attribute, cap1, cap2 = pair_string.split(':')\n",
    "\n",
    "    # Load images\n",
    "    X_images = torch.cat(load_dir(f'./{cap1}/*'))\n",
    "    Y_images = torch.cat(load_dir(f'./{cap2}/*'))\n",
    "\n",
    "    # Load precomputed embeddings for A_text and B_text\n",
    "    A_embedding_path = f\"{neut_embedding_base_path}{A_attribute}_ViT-L14.pt\"\n",
    "    B_embedding_path = f\"{neut_embedding_base_path}{B_attribute}_ViT-L14.pt\"\n",
    "    A_text = torch.load(A_embedding_path).detach().to(\"cpu\")\n",
    "    B_text = torch.load(B_embedding_path).detach().to(\"cpu\")\n",
    "\n",
    "    # Perform the test\n",
    "    test = Test(X_images, Y_images, A_text, B_text)\n",
    "    out = test.run()\n",
    "\n",
    "    # Create a dictionary for the current row and append to the list\n",
    "    df_row = {\n",
    "        'Name': A_attribute + ' vs. ' + B_attribute,\n",
    "        'X': cap1.split('/')[1],\n",
    "        'Y': cap2.split('/')[1],\n",
    "        'A': A_attribute.split('/')[1],\n",
    "        'B': B_attribute.split('/')[1],\n",
    "        'n_t': X_images.shape[0],\n",
    "        'n_a': A_text.shape[0],\n",
    "        'p_i': out[1],  # Assuming this is a scalar\n",
    "        'd_i': out[0]   # Assuming this is a scalar\n",
    "    }\n",
    "    df_rows.append(df_row)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(df_rows)\n",
    "\n",
    "# Display or save the DataFrame as needed\n",
    "print(df)\n",
    "df.to_csv('swapped_neuted_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2b8906",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(load_dir(\u001b[39m'\u001b[39;49m\u001b[39m./ieat/data/experiments/gender/male/*\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m Y_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./ieat/data/experiments/gender/female/*\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m A_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./ieat/data/experiments/gender/engineering/*\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/gender/female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/engineering/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/care/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Engineering', 'B': 'Caregiving', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cd09b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39;49m\u001b[39m./gender/male/*\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m Y_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./gender/female/*\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m A_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./gender/career/*\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 20\u001b[0m in \u001b[0;36mload_dir\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m prep \u001b[39m=\u001b[39m preprocess(img)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m emb \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode_image(prep)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m tmp\u001b[39m.\u001b[39mappend(emb\u001b[39m.\u001b[39mcpu())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "A_image = torch.cat(load_dir('./gender/career/*'))\n",
    "B_image = torch.cat(load_dir('./gender/family/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Career', 'B': 'Family', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/science/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/liberal-arts/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad799ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/engineering/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/care/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Engineering', 'B': 'Caregiving', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/career/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/family/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Career', 'B': 'Family', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34317bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/arab-muslim/other-people/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/arab-muslim/arab-muslim/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'other-people', 'Y': 'arab-muslim', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'european-american', 'Y': 'african-american', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/asian/european-american/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/asian/asian-american/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'european-american', 'Y': 'asian-american', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c08cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool-modern/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon-modern/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/skin-tone/light/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/skin-tone/dark/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/sexuality/straight/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/sexuality/gay/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'straight', 'Y': 'gay', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
