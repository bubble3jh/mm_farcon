{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a731f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import logging\n",
    "import pandas as pd\n",
    "import glob \n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import UnidentifiedImageError\n",
    "import subprocess\n",
    "from weat.test import Test\n",
    "import torch\n",
    "import clip\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda:2\")\n",
    "print(device)\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171b77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dwebpException(Exception):\n",
    "    pass\n",
    "\n",
    "def dwebp(file: str):\n",
    "    webp = subprocess.run(\n",
    "        f\"dwebp  {file} -quiet -o -\", shell=True, capture_output=True\n",
    "    )\n",
    "    if webp.returncode != 0:\n",
    "        raise dwebpException(webp.stderr.decode())\n",
    "    else:\n",
    "        return Image.open(BytesIO(webp.stdout))\n",
    "\n",
    "def load_dir(path):\n",
    "    tmp = []\n",
    "    \n",
    "    for file in glob.glob(path):\n",
    "        # 파일 확장자가 .json이면 무시\n",
    "        if os.path.splitext(file)[1].lower() == \".json\":\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                img = Image.open(file)\n",
    "            except UnidentifiedImageError:\n",
    "                if os.path.splitext(file)[1].lower() == \".webp\":\n",
    "                    img = dwebp(file)\n",
    "                  \n",
    "                else:\n",
    "                    raise\n",
    "            prep = preprocess(img).unsqueeze(0).to(device)\n",
    "            emb = model.encode_image(prep)\n",
    "            tmp.append(emb.cpu())\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c29583a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ieat_calc(X_Image_Paths, Y_Image_Paths, A_texts, B_texts, Names):\n",
    "    df = pd.DataFrame(columns=['Name', 'X', 'Y', 'A', 'B', 'n_t', 'n_a', 'p_i', 'd_i'])\n",
    "    for i in range(len(Names[0])):\n",
    "        X_image = torch.cat(load_dir(f'{X_Image_Paths[i]}*'))\n",
    "        Y_image = torch.cat(load_dir(f'{Y_Image_Paths[i]}*'))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            A_text = model.encode_text(A_texts[i]).to(\"cpu\")\n",
    "            B_text = model.encode_text(B_texts[i]).to(\"cpu\")\n",
    "                \n",
    "        test = Test(X_image, Y_image, A_text, B_text)\n",
    "        out = test.run()\n",
    "        result = {\n",
    "            'Name': Names[0][i],\n",
    "            'X': Names[1][i],\n",
    "            'Y': Names[2][i],\n",
    "            'A': Names[3][i],\n",
    "            'B': Names[4][i],\n",
    "            'n_t': X_image.shape[0],\n",
    "            'n_a': A_text.shape[0], \n",
    "            'p_i': out[1],\n",
    "            'd_i': out[0]\n",
    "        }\n",
    "        df = df.append(result, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1919689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "def load_caption(load_dir, model, device):\n",
    "    # 1. JSON 파일 읽기\n",
    "    with open(load_dir+'captions.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 2. \"caption\" 키의 값만 추출\n",
    "    captions = [item['caption'] for item in data]\n",
    "\n",
    "    return model.encode_text(clip.tokenize(captions).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601546e2",
   "metadata": {},
   "source": [
    "### Naive image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbffefa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/07 08:48:17 PM: Computing cosine similarities...\n",
      "09/07 08:48:17 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "09/07 08:48:17 PM: Computing pval...\n",
      "09/07 08:48:17 PM: Using non-parametric test\n",
      "09/07 08:48:17 PM: Drawing 9999 samples (and biasing by 1)\n",
      "09/07 08:48:17 PM: pval: 0.3603\n",
      "09/07 08:48:17 PM: computing effect size...\n",
      "09/07 08:48:17 PM: esize: 0.0805895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.08059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i      d_i\n",
       "0  Gender  Male  Female  Science  Arts   40   21  0.3603  0.08059"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "\n",
    "A_text = load_caption('./gender/science/', model, device).detach().to(\"cpu\")\n",
    "B_text = load_caption('./gender/liberal-arts/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e45d8",
   "metadata": {},
   "source": [
    "### Swapped image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "953aebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/07 08:39:00 PM: Computing cosine similarities...\n",
      "09/07 08:39:00 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "09/07 08:39:00 PM: Computing pval...\n",
      "09/07 08:39:00 PM: Using non-parametric test\n",
      "09/07 08:39:00 PM: Drawing 9999 samples (and biasing by 1)\n",
      "09/07 08:39:00 PM: pval: 0.0007\n",
      "09/07 08:39:00 PM: computing effect size...\n",
      "09/07 08:39:00 PM: esize: 0.932319\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.932319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i       d_i\n",
       "0  Gender  Male  Female  Science  Arts   21   40  0.0007  0.932319"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "# Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "\n",
    "# A_text = load_caption('./gender/science/', model, device).detach().to(\"cpu\")\n",
    "# B_text = load_caption('./gender/liberal-arts/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "X_image = torch.cat(load_dir('./gender/science/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/liberal-arts/*'))\n",
    "\n",
    "A_text = load_caption('./gender/male/', model, device).detach().to(\"cpu\")\n",
    "B_text = load_caption('./gender/female/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74669d13",
   "metadata": {},
   "source": [
    "### FarconVAE Neutralized image-caption bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "704076bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/07 08:44:13 PM: Computing cosine similarities...\n",
      "09/07 08:44:13 PM: Null hypothesis: no difference between X and Y in association to attributes A and B\n",
      "09/07 08:44:14 PM: Computing pval...\n",
      "09/07 08:44:14 PM: Using non-parametric test\n",
      "09/07 08:44:14 PM: Drawing 9999 samples (and biasing by 1)\n",
      "09/07 08:44:14 PM: pval: 0.2102\n",
      "09/07 08:44:14 PM: computing effect size...\n",
      "09/07 08:44:14 PM: esize: 0.256716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>n_t</th>\n",
       "      <th>n_a</th>\n",
       "      <th>p_i</th>\n",
       "      <th>d_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td>Science</td>\n",
       "      <td>Arts</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.256716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name     X       Y        A     B  n_t  n_a     p_i       d_i\n",
       "0  Gender  Male  Female  Science  Arts   21   21  0.2102  0.256716"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "# Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "\n",
    "# A_text = load_caption('./gender/science/', model, device).detach().to(\"cpu\")\n",
    "# B_text = load_caption('./gender/liberal-arts/', model, device).detach().to(\"cpu\")\n",
    "\n",
    "X_image = torch.cat(load_dir('./gender/science/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/liberal-arts/*'))\n",
    "\n",
    "# A_text = load_caption('./gender/male/', model, device).detach().to(\"cpu\")\n",
    "# B_text = load_caption('./gender/female/', model, device).detach().to(\"cpu\")\n",
    "A_text = torch.load('/data1/bubble3jh/farcon/git_FarconVAE/neut_embeddings/imgs/gender/male_ViT-L14.pt').detach().to(\"cpu\")\n",
    "B_text = torch.load('/data1/bubble3jh/farcon/git_FarconVAE/neut_embeddings/imgs/gender/female_ViT-L14.pt').detach().to(\"cpu\")\n",
    "\n",
    "\n",
    "test = Test(X_image, Y_image, A_text, B_text)\n",
    "out = test.run()\n",
    "\n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_text.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2b8906",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(load_dir(\u001b[39m'\u001b[39;49m\u001b[39m./ieat/data/experiments/gender/male/*\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m Y_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./ieat/data/experiments/gender/female/*\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m A_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./ieat/data/experiments/gender/engineering/*\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/gender/female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/engineering/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/care/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Engineering', 'B': 'Caregiving', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cd09b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39;49m\u001b[39m./gender/male/*\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m Y_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./gender/female/*\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m A_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(load_dir(\u001b[39m'\u001b[39m\u001b[39m./gender/career/*\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb 셀 20\u001b[0m in \u001b[0;36mload_dir\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m prep \u001b[39m=\u001b[39m preprocess(img)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m emb \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode_image(prep)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B39_lab/data1/bubble3jh/farcon/git_FarconVAE/data/mm/CLIP_iEAT.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m tmp\u001b[39m.\u001b[39mappend(emb\u001b[39m.\u001b[39mcpu())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "X_image = torch.cat(load_dir('./gender/male/*'))\n",
    "Y_image = torch.cat(load_dir('./gender/female/*'))\n",
    "A_image = torch.cat(load_dir('./gender/career/*'))\n",
    "B_image = torch.cat(load_dir('./gender/family/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Gender', 'X': 'Male', 'Y': 'Female', 'A': 'Career', 'B': 'Family', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/science/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/liberal-arts/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Science', 'B': 'Arts', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad799ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/engineering/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/care/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Engineering', 'B': 'Caregiving', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american-male/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american-female/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/gender/career/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/gender/family/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'African-American', 'Y': 'European-American', 'A': 'Career', 'B': 'Family', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34317bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/arab-muslim/other-people/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/arab-muslim/arab-muslim/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'other-people', 'Y': 'arab-muslim', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/race/european-american/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/race/african-american/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'european-american', 'Y': 'african-american', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/asian/european-american/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/asian/asian-american/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'european-american', 'Y': 'asian-american', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c08cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool-modern/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon-modern/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/weapon/white/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/weapon/black/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/skin-tone/light/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/skin-tone/dark/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/weapon/tool/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/weapon/weapon/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'white', 'Y': 'black', 'A': 'tool', 'B': 'weapon', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = torch.cat(load_dir('./ieat/data/experiments/sexuality/straight/*'))\n",
    "Y_image = torch.cat(load_dir('./ieat/data/experiments/sexuality/gay/*'))\n",
    "A_image = torch.cat(load_dir('./ieat/data/experiments/valence/pleasant/*'))\n",
    "B_image = torch.cat(load_dir('./ieat/data/experiments/valence/unpleasant/*'))\n",
    "\n",
    "test = Test(X_image, Y_image, A_image, B_image)\n",
    "out = test.run()\n",
    "        \n",
    "df = pd.DataFrame([{'Name': 'Ethnicity', 'X': 'straight', 'Y': 'gay', 'A': 'pleasant', 'B': 'unpleasant', 'n_t': X_image.shape[0], 'n_a': A_image.shape[0], 'p_i': out[1], 'd_i': out[0]}])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
